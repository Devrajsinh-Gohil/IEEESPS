{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea067c0e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-12T10:13:40.576867Z",
     "iopub.status.busy": "2024-09-12T10:13:40.576236Z",
     "iopub.status.idle": "2024-09-12T10:13:47.949635Z",
     "shell.execute_reply": "2024-09-12T10:13:47.948319Z"
    },
    "papermill": {
     "duration": 7.384908,
     "end_time": "2024-09-12T10:13:47.952829",
     "exception": false,
     "start_time": "2024-09-12T10:13:40.567921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b21a0a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T10:13:47.966869Z",
     "iopub.status.busy": "2024-09-12T10:13:47.966344Z",
     "iopub.status.idle": "2024-09-12T10:13:47.997026Z",
     "shell.execute_reply": "2024-09-12T10:13:47.995407Z"
    },
    "papermill": {
     "duration": 0.041055,
     "end_time": "2024-09-12T10:13:48.000001",
     "exception": false,
     "start_time": "2024-09-12T10:13:47.958946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "import torch.nn as nn\n",
    "class SEBlock(nn.Module):\n",
    "    \"\"\" Squeeze-and-Excitation Block \"\"\"\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.se = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, channels // reduction, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(channels // reduction, channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        scale = self.se(x)\n",
    "        return x * scale\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" Multi-Head Attention Module \"\"\"\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(d_model, num_heads, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "        return attn_output\n",
    "\n",
    "class RadioNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(RadioNet, self).__init__()\n",
    "\n",
    "        # Separate Convolutional Pathways for I and Q\n",
    "        self.q_conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            SEBlock(64),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            SEBlock(256),\n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.i_conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            SEBlock(64),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            SEBlock(256),\n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.feature_size = self._get_conv_output((1, 32, 32))\n",
    "\n",
    "        # Bidirectional LSTM with Layer Normalization\n",
    "        self.lstm = nn.LSTM(self.feature_size * 2, 512, num_layers=2, \n",
    "                            batch_first=True, bidirectional=True, dropout=0.3)\n",
    "        self.layer_norm = nn.LayerNorm(1024)  # Layer normalization after LSTM\n",
    "\n",
    "        # Multi-Head Attention with multiple heads\n",
    "        self.multi_head_attn = MultiHeadAttention(1024, num_heads=8)\n",
    "\n",
    "        # Enhanced Fully Connected Layers with Dense Connections\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.LeakyReLU(0.1)\n",
    "        )\n",
    "\n",
    "        self.output = nn.Linear(64, num_classes)\n",
    "\n",
    "    def _get_conv_output(self, shape):\n",
    "        input = torch.rand(1, *shape)\n",
    "        output = self.q_conv(input)\n",
    "        return int(torch.numel(output) / output.shape[0])\n",
    "\n",
    "    def forward(self, i_input, q_input):\n",
    "        q = self.q_conv(q_input)\n",
    "        q = q.view(q.size(0), -1)\n",
    "\n",
    "        i = self.i_conv(i_input)\n",
    "        i = i.view(i.size(0), -1)\n",
    "\n",
    "        combined = torch.cat((q, i), dim=1)\n",
    "        combined = combined.unsqueeze(1)  # Add sequence dimension\n",
    "\n",
    "        lstm_out, _ = self.lstm(combined)\n",
    "        lstm_out = self.layer_norm(lstm_out)\n",
    "\n",
    "        # Apply Multi-Head Attention\n",
    "        attn_output = self.multi_head_attn(lstm_out)\n",
    "        context = torch.sum(attn_output, dim=1)  # Sum up the attended output\n",
    "\n",
    "        x = self.fc(context)\n",
    "        x = self.output(x)\n",
    "\n",
    "        return torch.log_softmax(x, dim=1)\n",
    "\n",
    "# def create_model(num_classes):\n",
    "#     model = RadioNet(num_classes)\n",
    "#     learning_rate = 0.0003\n",
    "#     optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "#     loss_fn = nn.CrossEntropyLoss()\n",
    "#     scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "#     return model, optimizer, loss_fn, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4784a7ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T10:13:48.012857Z",
     "iopub.status.busy": "2024-09-12T10:13:48.012369Z",
     "iopub.status.idle": "2024-09-12T10:13:55.395327Z",
     "shell.execute_reply": "2024-09-12T10:13:55.394077Z"
    },
    "papermill": {
     "duration": 7.392485,
     "end_time": "2024-09-12T10:13:55.398068",
     "exception": false,
     "start_time": "2024-09-12T10:13:48.005583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17/3592900082.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  trained_model.load_state_dict(torch.load('/kaggle/input/radionet/pytorch/default/1/model_checkpoint.pth', map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RadioNet(\n",
       "  (q_conv): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1)\n",
       "    (3): SEBlock(\n",
       "      (se): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): LeakyReLU(negative_slope=0.1)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.1)\n",
       "    (11): SEBlock(\n",
       "      (se): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (i_conv): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1)\n",
       "    (3): SEBlock(\n",
       "      (se): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): LeakyReLU(negative_slope=0.1)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.1)\n",
       "    (11): SEBlock(\n",
       "      (se): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (lstm): LSTM(32768, 512, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (multi_head_attn): MultiHeadAttention(\n",
       "    (attention): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.1)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (4): LeakyReLU(negative_slope=0.1)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (7): LeakyReLU(negative_slope=0.1)\n",
       "    (8): Dropout(p=0.3, inplace=False)\n",
       "    (9): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (10): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (output): Linear(in_features=64, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model\n",
    "trained_model = RadioNet(num_classes=8)\n",
    "\n",
    "# Load the state dict, mapping it to the available device\n",
    "trained_model.load_state_dict(torch.load('/kaggle/input/radionet/pytorch/default/1/model_checkpoint.pth', map_location=device))\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "trained_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55805351",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T10:13:55.416345Z",
     "iopub.status.busy": "2024-09-12T10:13:55.415342Z",
     "iopub.status.idle": "2024-09-12T10:13:55.431907Z",
     "shell.execute_reply": "2024-09-12T10:13:55.429977Z"
    },
    "papermill": {
     "duration": 0.031297,
     "end_time": "2024-09-12T10:13:55.436216",
     "exception": false,
     "start_time": "2024-09-12T10:13:55.404919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, trained_model):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.q_conv = trained_model.q_conv\n",
    "        self.i_conv = trained_model.i_conv\n",
    "        self.lstm = trained_model.lstm\n",
    "        self.layer_norm = trained_model.layer_norm\n",
    "        self.multi_head_attn = trained_model.multi_head_attn\n",
    "        self.fc = trained_model.fc\n",
    "\n",
    "    def forward(self, i_input, q_input):\n",
    "        q = self.q_conv(q_input)\n",
    "        q = q.view(q.size(0), -1)\n",
    "\n",
    "        i = self.i_conv(i_input)\n",
    "        i = i.view(i.size(0), -1)\n",
    "\n",
    "        combined = torch.cat((q, i), dim=1)\n",
    "        combined = combined.unsqueeze(1)\n",
    "\n",
    "        lstm_out, _ = self.lstm(combined)\n",
    "        lstm_out = self.layer_norm(lstm_out)\n",
    "\n",
    "        attn_output = self.multi_head_attn(lstm_out)\n",
    "        context = torch.sum(attn_output, dim=1)\n",
    "\n",
    "        features = self.fc(context)\n",
    "        return features\n",
    "\n",
    "feature_extractor = FeatureExtractor(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31ca5a44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T10:13:55.454715Z",
     "iopub.status.busy": "2024-09-12T10:13:55.453913Z",
     "iopub.status.idle": "2024-09-12T10:13:55.460549Z",
     "shell.execute_reply": "2024-09-12T10:13:55.459350Z"
    },
    "papermill": {
     "duration": 0.019765,
     "end_time": "2024-09-12T10:13:55.463490",
     "exception": false,
     "start_time": "2024-09-12T10:13:55.443725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_features(model, i_input, q_input):\n",
    "    with torch.no_grad():\n",
    "        features = model(i_input, q_input)\n",
    "    return features.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f84a9b0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T10:13:55.477986Z",
     "iopub.status.busy": "2024-09-12T10:13:55.477013Z",
     "iopub.status.idle": "2024-09-12T10:13:55.490728Z",
     "shell.execute_reply": "2024-09-12T10:13:55.489264Z"
    },
    "papermill": {
     "duration": 0.024125,
     "end_time": "2024-09-12T10:13:55.493614",
     "exception": false,
     "start_time": "2024-09-12T10:13:55.469489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class RadioMLDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X).float().to(device)\n",
    "        self.y = torch.from_numpy(y.values).float().to(device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "def extract_features(model, dataloader):\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            # Separate I and Q components\n",
    "            i_input = batch_X[:, :, :, 0].unsqueeze(1)  # Shape: (batch_size, 1, 32, 32)\n",
    "            q_input = batch_X[:, :, :, 1].unsqueeze(1)  # Shape: (batch_size, 1, 32, 32)\n",
    "            \n",
    "            features = model.fc(model.multi_head_attn(model.layer_norm(model.lstm(torch.cat((\n",
    "                model.q_conv(q_input).view(q_input.size(0), -1),\n",
    "                model.i_conv(i_input).view(i_input.size(0), -1)\n",
    "            ), dim=1).unsqueeze(1))[0])).sum(dim=1))\n",
    "            \n",
    "            features_list.append(features.cpu().numpy())\n",
    "            labels_list.append(batch_y.cpu().numpy())\n",
    "    \n",
    "    return np.vstack(features_list), np.vstack(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1fb5854",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T10:13:55.507884Z",
     "iopub.status.busy": "2024-09-12T10:13:55.506632Z",
     "iopub.status.idle": "2024-09-12T10:13:57.839060Z",
     "shell.execute_reply": "2024-09-12T10:13:57.837691Z"
    },
    "papermill": {
     "duration": 2.342523,
     "end_time": "2024-09-12T10:13:57.841931",
     "exception": false,
     "start_time": "2024-09-12T10:13:55.499408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wandb login\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "my_secret = user_secrets.get_secret(\"wandb_api_key\") \n",
    "wandb.login(key=my_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d25c502b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T10:13:57.856694Z",
     "iopub.status.busy": "2024-09-12T10:13:57.856201Z",
     "iopub.status.idle": "2024-09-12T10:13:57.871655Z",
     "shell.execute_reply": "2024-09-12T10:13:57.870332Z"
    },
    "papermill": {
     "duration": 0.026435,
     "end_time": "2024-09-12T10:13:57.874911",
     "exception": false,
     "start_time": "2024-09-12T10:13:57.848476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def xgboost_kfold_cv(X, y, n_splits=5, random_state=42):\n",
    "    # Initialize wandb run\n",
    "    wandb.init(project=\"radioml-xgboost\", name=\"xgboost-kfold-cv\")\n",
    "    \n",
    "    # Log config\n",
    "    wandb.config.update({\n",
    "        \"n_splits\": n_splits,\n",
    "        \"random_state\": random_state,\n",
    "        \"model\": \"XGBoost\"\n",
    "    })\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    fold_accuracies = []\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X), 1):\n",
    "        print(f\"Fold {fold}\")\n",
    "\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=random_state)\n",
    "        xgb_clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=10, verbose=False)\n",
    "\n",
    "        y_pred = xgb_clf.predict(X_val)\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        fold_accuracies.append(accuracy)\n",
    "\n",
    "        print(f\"Fold {fold} Accuracy: {accuracy:.4f}\")\n",
    "        print(classification_report(y_val, y_pred))\n",
    "        print(\"--------------------\")\n",
    "\n",
    "        # Log metrics for this fold\n",
    "        wandb.log({\n",
    "            f\"fold_{fold}_accuracy\": accuracy,\n",
    "            \"fold\": fold\n",
    "        })\n",
    "\n",
    "        # Log feature importances\n",
    "        feature_imp = xgb_clf.feature_importances_\n",
    "        wandb.log({f\"feature_importance_fold_{fold}\": wandb.plot.bar(\n",
    "            wandb.Table(data=[[f\"feature_{i}\", imp] for i, imp in enumerate(feature_imp)],\n",
    "                        columns=[\"feature\", \"importance\"]),\n",
    "            \"feature\",\n",
    "            \"importance\",\n",
    "            title=f\"Feature Importances (Fold {fold})\"\n",
    "        )})\n",
    "\n",
    "    mean_accuracy = np.mean(fold_accuracies)\n",
    "    std_accuracy = np.std(fold_accuracies)\n",
    "    print(f\"Mean Accuracy: {mean_accuracy:.4f} (+/- {std_accuracy:.4f})\")\n",
    "\n",
    "    # Log final metrics\n",
    "    wandb.log({\n",
    "        \"mean_accuracy\": mean_accuracy,\n",
    "        \"std_accuracy\": std_accuracy\n",
    "    })\n",
    "\n",
    "    # Finish the wandb run\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46f32cdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T10:13:57.889529Z",
     "iopub.status.busy": "2024-09-12T10:13:57.889053Z",
     "iopub.status.idle": "2024-09-12T10:13:58.112151Z",
     "shell.execute_reply": "2024-09-12T10:13:58.110942Z"
    },
    "papermill": {
     "duration": 0.234068,
     "end_time": "2024-09-12T10:13:58.115256",
     "exception": false,
     "start_time": "2024-09-12T10:13:57.881188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "# Read the dataset\n",
    "dataset_file = h5py.File(\"/kaggle/input/radioml2018/GOLD_XYZ_OSC.0001_1024.hdf5\", \"r\")\n",
    "\n",
    "# Base modulation classes\n",
    "base_modulation_classes = [\n",
    "    'OOK', '4ASK', '8ASK', 'BPSK', 'QPSK', '8PSK', '16PSK', '32PSK',\n",
    "    '16APSK', '32APSK', '64APSK', '128APSK', '16QAM', '32QAM', '64QAM',\n",
    "    '128QAM', '256QAM', 'AM-SSB-WC', 'AM-SSB-SC', 'AM-DSB-WC', 'AM-DSB-SC',\n",
    "    'FM', 'GMSK', 'OQPSK'\n",
    "]\n",
    "\n",
    "# Selected modulation classes\n",
    "selected_modulation_classes = [\n",
    "    '4ASK', 'BPSK', 'QPSK', '16PSK', '16QAM', 'FM', 'AM-DSB-WC', '32APSK'\n",
    "]\n",
    "\n",
    "# Get the indices of selected modulation classes\n",
    "selected_classes_id = [base_modulation_classes.index(cls) for cls in selected_modulation_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1ebaf0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T10:13:58.130870Z",
     "iopub.status.busy": "2024-09-12T10:13:58.129988Z",
     "iopub.status.idle": "2024-09-12T10:14:10.950736Z",
     "shell.execute_reply": "2024-09-12T10:14:10.949627Z"
    },
    "papermill": {
     "duration": 12.831928,
     "end_time": "2024-09-12T10:14:10.953627",
     "exception": false,
     "start_time": "2024-09-12T10:13:58.121699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Number of SNRs (from 30 SNR to 22 SNR)\n",
    "N_SNR = 4 \n",
    "\n",
    "# Initialize placeholders for data\n",
    "X_data = None\n",
    "y_data = None\n",
    "\n",
    "# Loop through selected modulation classes\n",
    "for id in selected_classes_id:\n",
    "    # Load data slices based on indices\n",
    "    X_slice = dataset_file['X'][(106496*(id+1) - 4096*N_SNR) : 106496*(id+1)]\n",
    "    y_slice = dataset_file['Y'][(106496*(id+1) - 4096*N_SNR) : 106496*(id+1)]\n",
    "    \n",
    "    # Concatenate the slices to build the dataset\n",
    "    if X_data is not None:\n",
    "        X_data = np.concatenate([X_data, X_slice], axis=0)\n",
    "        y_data = np.concatenate([y_data, y_slice], axis=0)\n",
    "    else:\n",
    "        X_data = X_slice\n",
    "        y_data = y_slice\n",
    "\n",
    "# Reshape the X_data to the required shape (e.g., 32x32 with 2 channels)\n",
    "X_data = X_data.reshape(len(X_data), 32, 32, 2)\n",
    "\n",
    "# Convert y_data to a DataFrame for easier manipulation\n",
    "y_data_df = pd.DataFrame(y_data)\n",
    "\n",
    "# Drop columns where the sum is 0 (i.e., no modulation class data in that column)\n",
    "for column in y_data_df.columns:\n",
    "    if sum(y_data_df[column]) == 0:\n",
    "        y_data_df = y_data_df.drop(columns=[column])\n",
    "\n",
    "# Assign the remaining columns to match the selected modulation classes\n",
    "y_data_df.columns = selected_modulation_classes\n",
    "\n",
    "# Split the dataset into training and test sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18584c21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T10:14:10.968510Z",
     "iopub.status.busy": "2024-09-12T10:14:10.967662Z",
     "iopub.status.idle": "2024-09-12T11:32:43.550806Z",
     "shell.execute_reply": "2024-09-12T11:32:43.549231Z"
    },
    "papermill": {
     "duration": 4712.594172,
     "end_time": "2024-09-12T11:32:43.554084",
     "exception": false,
     "start_time": "2024-09-12T10:14:10.959912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from training data...\n",
      "Extracting features from test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdevcode03\u001b[0m (\u001b[33mdevcode03-gujarat-technological-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing K-fold cross-validation with XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.18.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20240912_113113-9nxvmuo2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mxgboost-kfold-cv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/devcode03-gujarat-technological-university/radioml-xgboost\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/devcode03-gujarat-technological-university/radioml-xgboost/runs/9nxvmuo2\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Accuracy: 0.9905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3296\n",
      "           1       1.00      1.00      1.00      3216\n",
      "           2       1.00      0.99      0.99      3200\n",
      "           3       1.00      1.00      1.00      3298\n",
      "           4       0.97      0.97      0.97      3253\n",
      "           5       0.97      0.96      0.96      3313\n",
      "           6       1.00      1.00      1.00      3329\n",
      "           7       1.00      1.00      1.00      3310\n",
      "\n",
      "    accuracy                           0.99     26215\n",
      "   macro avg       0.99      0.99      0.99     26215\n",
      "weighted avg       0.99      0.99      0.99     26215\n",
      "\n",
      "--------------------\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Accuracy: 0.9894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3292\n",
      "           1       1.00      1.00      1.00      3325\n",
      "           2       1.00      0.99      0.99      3261\n",
      "           3       0.99      1.00      1.00      3248\n",
      "           4       0.96      0.97      0.97      3359\n",
      "           5       0.97      0.95      0.96      3281\n",
      "           6       1.00      1.00      1.00      3169\n",
      "           7       1.00      1.00      1.00      3280\n",
      "\n",
      "    accuracy                           0.99     26215\n",
      "   macro avg       0.99      0.99      0.99     26215\n",
      "weighted avg       0.99      0.99      0.99     26215\n",
      "\n",
      "--------------------\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Accuracy: 0.9900\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3334\n",
      "           1       1.00      1.00      1.00      3246\n",
      "           2       0.99      1.00      0.99      3173\n",
      "           3       1.00      1.00      1.00      3307\n",
      "           4       0.96      0.98      0.97      3352\n",
      "           5       0.97      0.95      0.96      3248\n",
      "           6       1.00      1.00      1.00      3311\n",
      "           7       1.00      1.00      1.00      3243\n",
      "\n",
      "    accuracy                           0.99     26214\n",
      "   macro avg       0.99      0.99      0.99     26214\n",
      "weighted avg       0.99      0.99      0.99     26214\n",
      "\n",
      "--------------------\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Accuracy: 0.9906\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3248\n",
      "           1       1.00      1.00      1.00      3311\n",
      "           2       0.99      0.99      0.99      3306\n",
      "           3       1.00      1.00      1.00      3271\n",
      "           4       0.96      0.97      0.97      3143\n",
      "           5       0.97      0.96      0.97      3317\n",
      "           6       1.00      1.00      1.00      3306\n",
      "           7       1.00      1.00      1.00      3312\n",
      "\n",
      "    accuracy                           0.99     26214\n",
      "   macro avg       0.99      0.99      0.99     26214\n",
      "weighted avg       0.99      0.99      0.99     26214\n",
      "\n",
      "--------------------\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Accuracy: 0.9908\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3214\n",
      "           1       1.00      1.00      1.00      3286\n",
      "           2       1.00      1.00      1.00      3444\n",
      "           3       1.00      1.00      1.00      3260\n",
      "           4       0.97      0.98      0.97      3277\n",
      "           5       0.97      0.96      0.96      3225\n",
      "           6       1.00      1.00      1.00      3269\n",
      "           7       1.00      1.00      1.00      3239\n",
      "\n",
      "    accuracy                           0.99     26214\n",
      "   macro avg       0.99      0.99      0.99     26214\n",
      "weighted avg       0.99      0.99      0.99     26214\n",
      "\n",
      "--------------------\n",
      "Mean Accuracy: 0.9903 (+/- 0.0005)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fold ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: fold_1_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: fold_2_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: fold_3_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: fold_4_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: fold_5_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   mean_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    std_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            fold 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: fold_1_accuracy 0.9905\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: fold_2_accuracy 0.98943\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: fold_3_accuracy 0.99001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: fold_4_accuracy 0.99062\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: fold_5_accuracy 0.99081\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   mean_accuracy 0.99027\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    std_accuracy 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mxgboost-kfold-cv\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/devcode03-gujarat-technological-university/radioml-xgboost/runs/9nxvmuo2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/devcode03-gujarat-technological-university/radioml-xgboost\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 5 media file(s), 5 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240912_113113-9nxvmuo2/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n"
     ]
    }
   ],
   "source": [
    "# Create Dataset objects\n",
    "train_dataset = RadioMLDataset(X_train, y_train)\n",
    "test_dataset = RadioMLDataset(X_test, y_test)\n",
    "\n",
    "# Create DataLoader objects\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Extract features\n",
    "print(\"Extracting features from training data...\")\n",
    "X_train_features, y_train_features = extract_features(trained_model, train_loader)\n",
    "print(\"Extracting features from test data...\")\n",
    "X_test_features, y_test_features = extract_features(trained_model, test_loader)\n",
    "\n",
    "# Combine train and test features for K-fold CV\n",
    "X_all_features = np.vstack((X_train_features, X_test_features))\n",
    "y_all_features = np.vstack((y_train_features, y_test_features))\n",
    "\n",
    "# Convert multi-hot encoded labels to class indices\n",
    "y_all_indices = np.argmax(y_all_features, axis=1)\n",
    "\n",
    "# Perform K-fold cross-validation with XGBoost\n",
    "print(\"Performing K-fold cross-validation with XGBoost...\")\n",
    "xgboost_kfold_cv(X_all_features, y_all_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f6ad9f",
   "metadata": {
    "papermill": {
     "duration": 0.010213,
     "end_time": "2024-09-12T11:32:43.575711",
     "exception": false,
     "start_time": "2024-09-12T11:32:43.565498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1493018,
     "sourceId": 2468162,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 118112,
     "modelInstanceId": 93901,
     "sourceId": 112031,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4748.845126,
   "end_time": "2024-09-12T11:32:46.207513",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-12T10:13:37.362387",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
