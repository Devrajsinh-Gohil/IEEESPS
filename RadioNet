{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2468162,"sourceType":"datasetVersion","datasetId":1493018}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# imports\nimport h5py\nimport wandb\nimport numpy as np\nimport pandas as pd\nfrom time import time\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-08T19:30:23.957691Z","iopub.execute_input":"2024-09-08T19:30:23.958006Z","iopub.status.idle":"2024-09-08T19:30:31.201072Z","shell.execute_reply.started":"2024-09-08T19:30:23.957972Z","shell.execute_reply":"2024-09-08T19:30:31.200027Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Read the dataset\ndataset_file = h5py.File(\"/kaggle/input/radioml2018/GOLD_XYZ_OSC.0001_1024.hdf5\", \"r\")\n\n# Base modulation classes\nbase_modulation_classes = [\n    'OOK', '4ASK', '8ASK', 'BPSK', 'QPSK', '8PSK', '16PSK', '32PSK',\n    '16APSK', '32APSK', '64APSK', '128APSK', '16QAM', '32QAM', '64QAM',\n    '128QAM', '256QAM', 'AM-SSB-WC', 'AM-SSB-SC', 'AM-DSB-WC', 'AM-DSB-SC',\n    'FM', 'GMSK', 'OQPSK'\n]\n\n# Selected modulation classes\nselected_modulation_classes = [\n    '4ASK', 'BPSK', 'QPSK', '16PSK', '16QAM', 'FM', 'AM-DSB-WC', '32APSK'\n]\n\n# Get the indices of selected modulation classes\nselected_classes_id = [base_modulation_classes.index(cls) for cls in selected_modulation_classes]","metadata":{"execution":{"iopub.status.busy":"2024-09-08T19:30:34.897825Z","iopub.execute_input":"2024-09-08T19:30:34.898430Z","iopub.status.idle":"2024-09-08T19:30:34.924238Z","shell.execute_reply.started":"2024-09-08T19:30:34.898388Z","shell.execute_reply":"2024-09-08T19:30:34.923106Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Model\n\nclass SEBlock(nn.Module):\n    \"\"\" Squeeze-and-Excitation Block \"\"\"\n    def __init__(self, channels, reduction=16):\n        super(SEBlock, self).__init__()\n        self.se = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1),\n            nn.Conv2d(channels, channels // reduction, 1),\n            nn.ReLU(),\n            nn.Conv2d(channels // reduction, channels, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        scale = self.se(x)\n        return x * scale\n\nclass MultiHeadAttention(nn.Module):\n    \"\"\" Multi-Head Attention Module \"\"\"\n    def __init__(self, d_model, num_heads):\n        super(MultiHeadAttention, self).__init__()\n        self.attention = nn.MultiheadAttention(d_model, num_heads, batch_first=True)\n\n    def forward(self, x):\n        attn_output, _ = self.attention(x, x, x)\n        return attn_output\n\nclass RadioNet(nn.Module):\n    def __init__(self, num_classes):\n        super(RadioNet, self).__init__()\n\n        # Separate Convolutional Pathways for I and Q\n        self.q_conv = nn.Sequential(\n            nn.Conv2d(1, 64, 3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.LeakyReLU(0.1),\n            SEBlock(64),\n            nn.Conv2d(64, 128, 3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.1),\n            nn.MaxPool2d(2, stride=2),\n            nn.Conv2d(128, 256, 3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.1),\n            SEBlock(256),\n            nn.MaxPool2d(2, stride=2)\n        )\n\n        self.i_conv = nn.Sequential(\n            nn.Conv2d(1, 64, 3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.LeakyReLU(0.1),\n            SEBlock(64),\n            nn.Conv2d(64, 128, 3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.1),\n            nn.MaxPool2d(2, stride=2),\n            nn.Conv2d(128, 256, 3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.1),\n            SEBlock(256),\n            nn.MaxPool2d(2, stride=2)\n        )\n\n        self.feature_size = self._get_conv_output((1, 32, 32))\n\n        # Bidirectional LSTM with Layer Normalization\n        self.lstm = nn.LSTM(self.feature_size * 2, 512, num_layers=2, \n                            batch_first=True, bidirectional=True, dropout=0.3)\n        self.layer_norm = nn.LayerNorm(1024)  # Layer normalization after LSTM\n\n        # Multi-Head Attention with multiple heads\n        self.multi_head_attn = MultiHeadAttention(1024, num_heads=8)\n\n        # Enhanced Fully Connected Layers with Dense Connections\n        self.fc = nn.Sequential(\n            nn.Linear(1024, 1024),\n            nn.LeakyReLU(0.1),\n            nn.Dropout(0.5),\n            nn.Linear(1024, 512),\n            nn.LeakyReLU(0.1),\n            nn.Dropout(0.5),\n            nn.Linear(512, 256),\n            nn.LeakyReLU(0.1),\n            nn.Dropout(0.3),\n            nn.Linear(256, 64),\n            nn.LeakyReLU(0.1)\n        )\n\n        self.output = nn.Linear(64, num_classes)\n\n    def _get_conv_output(self, shape):\n        input = torch.rand(1, *shape)\n        output = self.q_conv(input)\n        return int(torch.numel(output) / output.shape[0])\n\n    def forward(self, i_input, q_input):\n        q = self.q_conv(q_input)\n        q = q.view(q.size(0), -1)\n\n        i = self.i_conv(i_input)\n        i = i.view(i.size(0), -1)\n\n        combined = torch.cat((q, i), dim=1)\n        combined = combined.unsqueeze(1)  # Add sequence dimension\n\n        lstm_out, _ = self.lstm(combined)\n        lstm_out = self.layer_norm(lstm_out)\n\n        # Apply Multi-Head Attention\n        attn_output = self.multi_head_attn(lstm_out)\n        context = torch.sum(attn_output, dim=1)  # Sum up the attended output\n\n        x = self.fc(context)\n        x = self.output(x)\n\n        return torch.log_softmax(x, dim=1)\n\ndef create_model(num_classes):\n    model = RadioNet(num_classes)\n    learning_rate = 0.0003\n    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n    loss_fn = nn.CrossEntropyLoss()\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n    return model, optimizer, loss_fn, scheduler","metadata":{"execution":{"iopub.status.busy":"2024-09-08T19:31:05.881750Z","iopub.execute_input":"2024-09-08T19:31:05.882628Z","iopub.status.idle":"2024-09-08T19:31:05.907537Z","shell.execute_reply.started":"2024-09-08T19:31:05.882588Z","shell.execute_reply":"2024-09-08T19:31:05.906656Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Initialize model, optimizer, and loss function\nnum_classes = len(selected_modulation_classes)\nmodel, optimizer, loss_fn, scheduler = create_model(num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-09-08T19:31:16.452091Z","iopub.execute_input":"2024-09-08T19:31:16.452852Z","iopub.status.idle":"2024-09-08T19:31:19.005504Z","shell.execute_reply.started":"2024-09-08T19:31:16.452812Z","shell.execute_reply":"2024-09-08T19:31:19.004395Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check if multiple GPUs are available and use them if possible\nif torch.cuda.device_count() > 1:\n    print(f\"Let's use {torch.cuda.device_count()} GPUs!\")\n    # Wrap the model with DataParallel to parallelize across available GPUs\n    model = nn.DataParallel(model)\n\n# Set device to CUDA if available, otherwise fallback to CPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Move the model to the appropriate device (GPU or CPU)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-08T19:31:35.130730Z","iopub.execute_input":"2024-09-08T19:31:35.131438Z","iopub.status.idle":"2024-09-08T19:31:35.657736Z","shell.execute_reply.started":"2024-09-08T19:31:35.131397Z","shell.execute_reply":"2024-09-08T19:31:35.656762Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Let's use 2 GPUs!\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DataParallel(\n  (module): RadioNet(\n    (q_conv): Sequential(\n      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): LeakyReLU(negative_slope=0.1)\n      (3): SEBlock(\n        (se): Sequential(\n          (0): AdaptiveAvgPool2d(output_size=1)\n          (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n          (2): ReLU()\n          (3): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n          (4): Sigmoid()\n        )\n      )\n      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (6): LeakyReLU(negative_slope=0.1)\n      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (10): LeakyReLU(negative_slope=0.1)\n      (11): SEBlock(\n        (se): Sequential(\n          (0): AdaptiveAvgPool2d(output_size=1)\n          (1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n          (2): ReLU()\n          (3): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n          (4): Sigmoid()\n        )\n      )\n      (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    )\n    (i_conv): Sequential(\n      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): LeakyReLU(negative_slope=0.1)\n      (3): SEBlock(\n        (se): Sequential(\n          (0): AdaptiveAvgPool2d(output_size=1)\n          (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n          (2): ReLU()\n          (3): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n          (4): Sigmoid()\n        )\n      )\n      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (6): LeakyReLU(negative_slope=0.1)\n      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (10): LeakyReLU(negative_slope=0.1)\n      (11): SEBlock(\n        (se): Sequential(\n          (0): AdaptiveAvgPool2d(output_size=1)\n          (1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n          (2): ReLU()\n          (3): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n          (4): Sigmoid()\n        )\n      )\n      (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    )\n    (lstm): LSTM(32768, 512, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    (multi_head_attn): MultiHeadAttention(\n      (attention): MultiheadAttention(\n        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n      )\n    )\n    (fc): Sequential(\n      (0): Linear(in_features=1024, out_features=1024, bias=True)\n      (1): LeakyReLU(negative_slope=0.1)\n      (2): Dropout(p=0.5, inplace=False)\n      (3): Linear(in_features=1024, out_features=512, bias=True)\n      (4): LeakyReLU(negative_slope=0.1)\n      (5): Dropout(p=0.5, inplace=False)\n      (6): Linear(in_features=512, out_features=256, bias=True)\n      (7): LeakyReLU(negative_slope=0.1)\n      (8): Dropout(p=0.3, inplace=False)\n      (9): Linear(in_features=256, out_features=64, bias=True)\n      (10): LeakyReLU(negative_slope=0.1)\n    )\n    (output): Linear(in_features=64, out_features=8, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Number of SNRs (from 30 SNR to 22 SNR)\nN_SNR = 4 \n\n# Initialize placeholders for data\nX_data = None\ny_data = None\n\n# Loop through selected modulation classes\nfor id in selected_classes_id:\n    # Load data slices based on indices\n    X_slice = dataset_file['X'][(106496*(id+1) - 4096*N_SNR) : 106496*(id+1)]\n    y_slice = dataset_file['Y'][(106496*(id+1) - 4096*N_SNR) : 106496*(id+1)]\n    \n    # Concatenate the slices to build the dataset\n    if X_data is not None:\n        X_data = np.concatenate([X_data, X_slice], axis=0)\n        y_data = np.concatenate([y_data, y_slice], axis=0)\n    else:\n        X_data = X_slice\n        y_data = y_slice\n\n# Reshape the X_data to the required shape (e.g., 32x32 with 2 channels)\nX_data = X_data.reshape(len(X_data), 32, 32, 2)\n\n# Convert y_data to a DataFrame for easier manipulation\ny_data_df = pd.DataFrame(y_data)\n\n# Drop columns where the sum is 0 (i.e., no modulation class data in that column)\nfor column in y_data_df.columns:\n    if sum(y_data_df[column]) == 0:\n        y_data_df = y_data_df.drop(columns=[column])\n\n# Assign the remaining columns to match the selected modulation classes\ny_data_df.columns = selected_modulation_classes\n\n# Split the dataset into training and test sets (80-20 split)\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data_df, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-09-08T19:31:42.941001Z","iopub.execute_input":"2024-09-08T19:31:42.941807Z","iopub.status.idle":"2024-09-08T19:31:59.970595Z","shell.execute_reply.started":"2024-09-08T19:31:42.941764Z","shell.execute_reply":"2024-09-08T19:31:59.969607Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Define the custom Dataset class\nclass RadioMLDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = torch.from_numpy(X).float().to(device)  # Convert X to a PyTorch tensor\n        self.y = torch.from_numpy(y.values).float().to(device)  # Convert y to a PyTorch tensor\n    \n    def __len__(self):\n        return len(self.X)  # Return the number of samples in the dataset\n    \n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]  # Return a sample and its corresponding label\n\n# Create Dataset objects for training and testing data\ntrain_dataset = RadioMLDataset(X_train, y_train)\ntest_dataset = RadioMLDataset(X_test, y_test)\n\n# Create DataLoader objects for batching and shuffling data\nbatch_size = 32  # You can adjust the batch size as needed\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)  # Shuffle training data\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)  # No shuffling for test data\n\n# Example of how to use the DataLoader\nfor batch_X, batch_y in train_loader:\n    # batch_X and batch_y are PyTorch tensors\n    # batch_X shape: (batch_size, 32, 32, 2)\n    # batch_y shape: (batch_size, num_classes)\n    print(f\"Batch X shape: {batch_X.shape}\")\n    print(f\"Batch y shape: {batch_y.shape}\")\n    break  # This breaks the loop after the first batch, just to demonstrate","metadata":{"execution":{"iopub.status.busy":"2024-09-08T19:32:31.832639Z","iopub.execute_input":"2024-09-08T19:32:31.833628Z","iopub.status.idle":"2024-09-08T19:32:32.130524Z","shell.execute_reply.started":"2024-09-08T19:32:31.833582Z","shell.execute_reply":"2024-09-08T19:32:32.129408Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Batch X shape: torch.Size([32, 32, 32, 2])\nBatch y shape: torch.Size([32, 8])\n","output_type":"stream"}]},{"cell_type":"code","source":"# Training parameters\nepochs = 25\npatience = 10\nbest_acc = 0\nno_improve = 0\npath_checkpoint = \"model_checkpoint.pth\"\n\n# Training loop\ntrain_losses, train_accs, val_losses, val_accs = [], [], [], []","metadata":{"execution":{"iopub.status.busy":"2024-09-08T19:32:37.138316Z","iopub.execute_input":"2024-09-08T19:32:37.138759Z","iopub.status.idle":"2024-09-08T19:32:37.144522Z","shell.execute_reply.started":"2024-09-08T19:32:37.138701Z","shell.execute_reply":"2024-09-08T19:32:37.143428Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# wandb login\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\nmy_secret = user_secrets.get_secret(\"wandb_api_key\") \nwandb.login(key=my_secret)","metadata":{"execution":{"iopub.status.busy":"2024-09-08T19:32:40.376511Z","iopub.execute_input":"2024-09-08T19:32:40.377216Z","iopub.status.idle":"2024-09-08T19:32:42.433187Z","shell.execute_reply.started":"2024-09-08T19:32:40.377176Z","shell.execute_reply":"2024-09-08T19:32:42.432231Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# Initialize wandb\nwandb.init(project=\"RadioML\", name=\"RadioNet\")\n\n# Log model architecture\nwandb.watch(model)\n\nfor epoch in range(epochs):\n    # Set model to training mode\n    model.train()\n    train_loss, train_correct = 0, 0\n    # Training loop\n    for batch_X, batch_y in train_loader:\n        # Split the input into I and Q components\n        i_input = batch_X[:, :, :, 0].unsqueeze(1)  # I component\n        q_input = batch_X[:, :, :, 1].unsqueeze(1)  # Q component\n        # Zero out the gradients\n        optimizer.zero_grad()\n        # Forward pass through the model\n        outputs = model(i_input, q_input)\n        # Compute loss\n        loss = loss_fn(outputs, batch_y)\n        # Backpropagation\n        loss.backward()\n        # Update model parameters\n        optimizer.step()\n        # Accumulate training loss and correct predictions\n        train_loss += loss.item()\n        train_correct += (outputs.argmax(1) == batch_y.argmax(1)).sum().item()\n    # Compute average training loss and accuracy\n    train_loss /= len(train_loader)\n    train_acc = train_correct / len(train_dataset)\n    # Validation loop (without gradient updates)\n    model.eval()\n    val_loss, val_correct = 0, 0\n    with torch.no_grad():\n        for batch_X, batch_y in test_loader:\n            # Split the input into I and Q components\n            i_input = batch_X[:, :, :, 0].unsqueeze(1)  # I component\n            q_input = batch_X[:, :, :, 1].unsqueeze(1)  # Q component\n            # Forward pass through the model\n            outputs = model(i_input, q_input)\n            # Compute validation loss\n            val_loss += loss_fn(outputs, batch_y).item()\n            # Accumulate correct predictions\n            val_correct += (outputs.argmax(1) == batch_y.argmax(1)).sum().item()\n    # Compute average validation loss and accuracy\n    val_loss /= len(test_loader)\n    val_acc = val_correct / len(test_dataset)\n    # Save loss and accuracy for later plotting\n    train_losses.append(train_loss)\n    train_accs.append(train_acc)\n    val_losses.append(val_loss)\n    val_accs.append(val_acc)\n\n    # Log metrics to wandb\n    wandb.log({\n        \"epoch\": epoch + 1,\n        \"train_loss\": train_loss,\n        \"train_acc\": train_acc,\n        \"val_loss\": val_loss,\n        \"val_acc\": val_acc,\n        \"learning_rate\": optimizer.param_groups[0]['lr']\n    })\n\n    # Print progress for this epoch\n    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n    # Step the learning rate scheduler based on validation loss\n    scheduler.step(val_loss)\n    # Early stopping and model checkpointing\n    if val_acc > best_acc:\n        best_acc = val_acc\n        torch.save(model.state_dict(), path_checkpoint)  # Save the model checkpoint\n        wandb.save(path_checkpoint)  # Save the model checkpoint to wandb\n        no_improve = 0  # Reset no improvement counter\n    else:\n        no_improve += 1\n        if no_improve == patience:\n            print(\"Early stopping\")\n            break\n\n# Finish the wandb run\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-09-08T19:32:47.571108Z","iopub.execute_input":"2024-09-08T19:32:47.572249Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdevcode03\u001b[0m (\u001b[33mdevcode03-gujarat-technological-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.9 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240908_193247-d9nv2kbx</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/devcode03-gujarat-technological-university/RadioML/runs/d9nv2kbx' target=\"_blank\">RadioNet</a></strong> to <a href='https://wandb.ai/devcode03-gujarat-technological-university/RadioML' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/devcode03-gujarat-technological-university/RadioML' target=\"_blank\">https://wandb.ai/devcode03-gujarat-technological-university/RadioML</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/devcode03-gujarat-technological-university/RadioML/runs/d9nv2kbx' target=\"_blank\">https://wandb.ai/devcode03-gujarat-technological-university/RadioML/runs/d9nv2kbx</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}